# ã‚¿ã‚¹ã‚¯08: ãƒãƒƒãƒå‡¦ç†å®Ÿè£…

## ğŸ“‹ æ¦‚è¦

| é …ç›® | å†…å®¹ |
|------|------|
| æ‹…å½“ | ğŸ¤– AI Agent |
| æ‰€è¦æ™‚é–“ | 1.5æ™‚é–“ |
| å‰ææ¡ä»¶ | ã‚¿ã‚¹ã‚¯07å®Œäº† |
| æˆæœç‰© | Redis ã‚­ãƒ¥ãƒ¼ã€ARQ ãƒ¯ãƒ¼ã‚«ãƒ¼ |

---

## ğŸ“ å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«

### backend/app/workers/tasks.py

```python
"""ARQ ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¿ã‚¹ã‚¯"""
from typing import Any, Optional
from uuid import UUID
from arq import create_pool
from arq.connections import RedisSettings
from app.core.config import get_settings
from app.db.database import async_session_maker
from app.services.article_generator import article_generator

settings = get_settings()


async def generate_article_task(ctx: dict, article_id: str, options: Optional[dict] = None) -> dict:
    """è¨˜äº‹ç”Ÿæˆã‚¿ã‚¹ã‚¯"""
    async with async_session_maker() as db:
        result = await article_generator.generate(db, UUID(article_id), options)
        await db.commit()
        return {
            "success": result.success,
            "article_id": str(result.article_id),
            "title": result.title,
            "errors": result.errors
        }


async def batch_generate_task(ctx: dict, article_ids: list[str], options: Optional[dict] = None) -> dict:
    """ãƒãƒƒãƒç”Ÿæˆã‚¿ã‚¹ã‚¯"""
    results = []
    for article_id in article_ids:
        result = await generate_article_task(ctx, article_id, options)
        results.append(result)

    success_count = sum(1 for r in results if r["success"])
    return {
        "total": len(article_ids),
        "success": success_count,
        "failed": len(article_ids) - success_count,
        "results": results
    }


class WorkerSettings:
    """ARQ ãƒ¯ãƒ¼ã‚«ãƒ¼è¨­å®š"""
    functions = [generate_article_task, batch_generate_task]
    redis_settings = RedisSettings.from_dsn(str(settings.redis_url))
    max_jobs = 10
    job_timeout = 300  # 5åˆ†
```

### backend/app/api/batch.py

```python
"""ãƒãƒƒãƒå‡¦ç† API"""
from uuid import UUID, uuid4
from fastapi import APIRouter
from pydantic import BaseModel, Field
from arq import create_pool
from arq.connections import RedisSettings
from app.core.config import get_settings

settings = get_settings()
router = APIRouter(prefix="/batch", tags=["Batch"])


class BatchGenerateRequest(BaseModel):
    article_ids: list[UUID] = Field(..., min_length=1, max_length=100)
    options: dict | None = None


class BatchResponse(BaseModel):
    job_id: str
    total: int
    message: str


@router.post("/generate", response_model=BatchResponse)
async def batch_generate(data: BatchGenerateRequest):
    pool = await create_pool(RedisSettings.from_dsn(str(settings.redis_url)))
    job_id = str(uuid4())

    await pool.enqueue_job(
        "batch_generate_task",
        [str(aid) for aid in data.article_ids],
        data.options,
        _job_id=job_id
    )
    await pool.close()

    return BatchResponse(
        job_id=job_id,
        total=len(data.article_ids),
        message=f"Batch job started for {len(data.article_ids)} articles"
    )


@router.get("/status/{job_id}")
async def get_batch_status(job_id: str):
    pool = await create_pool(RedisSettings.from_dsn(str(settings.redis_url)))
    job = await pool.job(job_id)
    await pool.close()

    if not job:
        return {"job_id": job_id, "status": "not_found"}

    info = await job.info()
    return {
        "job_id": job_id,
        "status": info.status if info else "unknown",
        "result": await job.result() if info and info.status == "complete" else None
    }
```

### backend/app/api/__init__.pyï¼ˆæ›´æ–°ï¼‰

```python
"""API ãƒ«ãƒ¼ã‚¿ãƒ¼é›†ç´„"""
from fastapi import APIRouter
from app.api.articles import router as articles_router
from app.api.batch import router as batch_router
from app.api.categories import router as categories_router
from app.api.generate import router as generate_router
from app.api.sheets import router as sheets_router
from app.api.wordpress import router as wordpress_router

api_router = APIRouter(prefix="/api")
api_router.include_router(categories_router)
api_router.include_router(articles_router)
api_router.include_router(sheets_router)
api_router.include_router(wordpress_router)
api_router.include_router(generate_router)
api_router.include_router(batch_router)
```

### docker-compose.ymlï¼ˆãƒ¯ãƒ¼ã‚«ãƒ¼è¿½åŠ ï¼‰

```yaml
  worker:
    build: ./backend
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@db:5432/article_generator
      - REDIS_URL=redis://redis:6379
    env_file:
      - .env
    volumes:
      - ./backend:/app
    depends_on:
      - db
      - redis
    command: arq app.workers.tasks.WorkerSettings
```

---

## âœ… å®Œäº†æ¡ä»¶

```bash
# ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’èµ·å‹•
docker compose up -d worker

# ãƒãƒƒãƒç”Ÿæˆã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
curl -X POST http://localhost:8000/api/batch/generate \
  -H "Content-Type: application/json" \
  -d '{"article_ids":["<è¨˜äº‹ID1>","<è¨˜äº‹ID2>"]}'

# ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¢ºèª
curl http://localhost:8000/api/batch/status/<JOB_ID>

# ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ­ã‚°ã§å‡¦ç†ã‚’ç¢ºèª
docker compose logs -f worker
```

---

## ğŸ“Œ æ¬¡ã®ã‚¿ã‚¹ã‚¯

ã‚¿ã‚¹ã‚¯08å®Œäº†å¾Œã€**ã‚¿ã‚¹ã‚¯09: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å®Ÿè£…** ã«é€²ã‚“ã§ãã ã•ã„ã€‚
